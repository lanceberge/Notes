name: Convert to HTML and Push to S3

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

  workflow_dispatch:


jobs:
  get_modified_files:
    runs-on: ubuntu-latest

    outputs:
      modified_files: ${{ steps.set_env.outputs.modified_files }}
      deleted_files: ${{ steps.set_env.outputs.deleted_files }}

    env:
      AWS_S3_BUCKET: "s3://braindump-bucket"


    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0


      - name: Get Modified Files
        id: files_list
        run: |
          first_commit='${{ github.event.before }}'
          last_commit='${{ github.event.after }}'
          ALL_MODIFIED_FILES=$(git diff --name-status "$first_commit" "$last_commit")
          if [ -z "$ALL_MODIFIED_FILES" ]; then
              echo "No modified files. Exiting."
              exit 0
          fi

          echo "All Modified files:"
          echo "$ALL_MODIFIED_FILES"
          ALL_RENAMED_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^R' )
          ADDED_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^A' | cut -f2)

          # We will delete all files that were renamed and convert/write all
          # of the files that they got renamed to

          ## TODO optimization - only convert if there's a diff for the modified file
          ## otherwise do aws s3 mv
          RENAMED_MODIFIED_FILES=$(echo "$ALL_RENAMED_FILES" | cut -f3)
          MODIFIED_ONLY_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^M' | cut -f2)
          MODIFIED_FILES=$(echo "$MODIFIED_ONLY_FILES" "$RENAMED_MODIFIED_FILES" "$ADDED_FILES" | tr '\n' ' ')
          echo "Modified Files:"
          echo "$MODIFIED_FILES"
          echo "MODIFIED_FILES=$MODIFIED_FILES >> $GITHUB_ENV

          RENAMED_DELETED_FILES=$(echo "$ALL_RENAMED_FILES" | cut -f2)
          DELETED_ONLY_FILES=$(echo "$ALL_MODIFIED_FILES" | grep -E '^D' | cut -f2)
          DELETED_FILES=$(echo "$DELETED_ONLY_FILES" "$RENAMED_DELETED_FILES" | tr '\n' ' ')
          echo "Deleted Files:"
          echo "$DELETED_FILES"
          echo "DELETED_FILES=$DELETED_FILES" >> $GITHUB_ENV


  write_to_s3:
    runs-on: ubuntu_latest
    needs: get_modified_files

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: 'us-east-2'


      - name: Install Pandoc
        if: needs.get_modified_files.outputs.modified_files != ''
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc


      - name: Convert and Push
        if: needs.get_modified_files.outputs.modified_files != ''
        run: |
          for file in ${{ needs.get_modified_files.outputs.modified_files }}
              if [[ "$file" == *.org ]]; then
                      HTML_FILE=${file%.org}.html
                      pandoc "$file" -o "$HTML_FILE"
                      file="$HTML_FILE"
              fi

              aws s3 mv "$file" "$AWS_S3_BUCKET/$file"

          find "." -type f -name "*.html" -print0 | xargs -0 rm


      - name: Delete Files
        if: needs.get_modified_files.outputs.deleted_files != ''
        run: |
          for file in ${{ needs.get_modified_files.outputs.deleted_files }}
              aws s3 rm "$file" "$AWS_S3_BUCKET/$file"
          done

# TODO set up a way to ignore files
